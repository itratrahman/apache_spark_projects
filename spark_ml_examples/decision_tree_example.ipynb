{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import spark modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"PythonPi\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup spark configuration and create a spark context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irisData = sc.textFile(\"./input/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cache the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "./input/iris.csv MapPartitionsRDD[1] at textFile at <unknown>:0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cleanup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the header line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLines = irisData.filter(lambda x: \"Sepal\" not in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLines.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split each line by the commas\n",
    "parts = dataLines.map(lambda l: l.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map the RDD into row format\n",
    "irisMap = parts.map(lambda p: Row(SEPAL_LENGTH = float(p[0]),\n",
    "                                  SEPAL_WIDTH = float(p[1]),\n",
    "                                  PETAL_LENGTH = float(p[2]),\n",
    "                                  PETAL_WIDTH = float(p[3]),\n",
    "                                  SPECIES = p[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the rdd\n",
    "irisDf = spark.createDataFrame(irisMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PETAL_LENGTH: double, PETAL_WIDTH: double, SEPAL_LENGTH: double, SEPAL_WIDTH: double, SPECIES: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache the datafram\n",
    "irisDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|PETAL_LENGTH|PETAL_WIDTH|SEPAL_LENGTH|SEPAL_WIDTH|SPECIES|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         1.4|        0.2|         5.1|        3.5| setosa|\n",
      "|         1.4|        0.2|         4.9|        3.0| setosa|\n",
      "|         1.3|        0.2|         4.7|        3.2| setosa|\n",
      "|         1.5|        0.2|         4.6|        3.1| setosa|\n",
      "|         1.4|        0.2|         5.0|        3.6| setosa|\n",
      "|         1.7|        0.4|         5.4|        3.9| setosa|\n",
      "|         1.4|        0.3|         4.6|        3.4| setosa|\n",
      "|         1.5|        0.2|         5.0|        3.4| setosa|\n",
      "|         1.4|        0.2|         4.4|        2.9| setosa|\n",
      "|         1.5|        0.1|         4.9|        3.1| setosa|\n",
      "|         1.5|        0.2|         5.4|        3.7| setosa|\n",
      "|         1.6|        0.2|         4.8|        3.4| setosa|\n",
      "|         1.4|        0.1|         4.8|        3.0| setosa|\n",
      "|         1.1|        0.1|         4.3|        3.0| setosa|\n",
      "|         1.2|        0.2|         5.8|        4.0| setosa|\n",
      "|         1.5|        0.4|         5.7|        4.4| setosa|\n",
      "|         1.3|        0.4|         5.4|        3.9| setosa|\n",
      "|         1.4|        0.3|         5.1|        3.5| setosa|\n",
      "|         1.7|        0.3|         5.7|        3.8| setosa|\n",
      "|         1.5|        0.3|         5.1|        3.8| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the labels into numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol = \"SPECIES\", outputCol=\"IND_SPECIES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "si_model = stringIndexer.fit(irisDf)\n",
    "irisNormDf = si_model.transform(irisDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Species='versicolor', IND_SPECIES=0.0),\n",
       " Row(Species='setosa', IND_SPECIES=2.0),\n",
       " Row(Species='virginica', IND_SPECIES=1.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisNormDf.select(\"Species\", \"IND_SPECIES\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PETAL_LENGTH: double, PETAL_WIDTH: double, SEPAL_LENGTH: double, SEPAL_WIDTH: double, SPECIES: string, IND_SPECIES: double]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisNormDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+-----------+\n",
      "|PETAL_LENGTH|PETAL_WIDTH|SEPAL_LENGTH|SEPAL_WIDTH|SPECIES|IND_SPECIES|\n",
      "+------------+-----------+------------+-----------+-------+-----------+\n",
      "|         1.4|        0.2|         5.1|        3.5| setosa|        2.0|\n",
      "|         1.4|        0.2|         4.9|        3.0| setosa|        2.0|\n",
      "|         1.3|        0.2|         4.7|        3.2| setosa|        2.0|\n",
      "|         1.5|        0.2|         4.6|        3.1| setosa|        2.0|\n",
      "|         1.4|        0.2|         5.0|        3.6| setosa|        2.0|\n",
      "|         1.7|        0.4|         5.4|        3.9| setosa|        2.0|\n",
      "|         1.4|        0.3|         4.6|        3.4| setosa|        2.0|\n",
      "|         1.5|        0.2|         5.0|        3.4| setosa|        2.0|\n",
      "|         1.4|        0.2|         4.4|        2.9| setosa|        2.0|\n",
      "|         1.5|        0.1|         4.9|        3.1| setosa|        2.0|\n",
      "|         1.5|        0.2|         5.4|        3.7| setosa|        2.0|\n",
      "|         1.6|        0.2|         4.8|        3.4| setosa|        2.0|\n",
      "|         1.4|        0.1|         4.8|        3.0| setosa|        2.0|\n",
      "|         1.1|        0.1|         4.3|        3.0| setosa|        2.0|\n",
      "|         1.2|        0.2|         5.8|        4.0| setosa|        2.0|\n",
      "|         1.5|        0.4|         5.7|        4.4| setosa|        2.0|\n",
      "|         1.3|        0.4|         5.4|        3.9| setosa|        2.0|\n",
      "|         1.4|        0.3|         5.1|        3.5| setosa|        2.0|\n",
      "|         1.7|        0.3|         5.7|        3.8| setosa|        2.0|\n",
      "|         1.5|        0.3|         5.1|        3.8| setosa|        2.0|\n",
      "+------------+-----------+------------+-----------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisNormDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform data analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|summary|      PETAL_LENGTH|       PETAL_WIDTH|      SEPAL_LENGTH|       SEPAL_WIDTH|  SPECIES|       IND_SPECIES|\n",
      "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|  count|               150|               150|               150|               150|      150|               150|\n",
      "|   mean| 3.758000000000001|1.1993333333333331| 5.843333333333332|3.0573333333333337|     null|               1.0|\n",
      "| stddev|1.7652982332594662|0.7622376689603467|0.8280661279778634|0.4358662849366978|     null|0.8192319205190404|\n",
      "|    min|               1.0|               0.1|               4.3|               2.0|   setosa|               0.0|\n",
      "|    max|               6.9|               2.5|               7.9|               4.4|virginica|               2.0|\n",
      "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisNormDf.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation between the target variables and the feature variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation to IND_SPECIES for PETAL_LENGTH -0.649241830764174\n",
      "Correlation to IND_SPECIES for PETAL_WIDTH -0.5803770334306263\n",
      "Correlation to IND_SPECIES for SEPAL_LENGTH -0.46003915650023686\n",
      "Correlation to IND_SPECIES for SEPAL_WIDTH 0.6183715308237434\n",
      "Correlation to IND_SPECIES for IND_SPECIES 1.0\n"
     ]
    }
   ],
   "source": [
    "# iterate through each column in the dataframe\n",
    "for i in irisNormDf.columns:\n",
    "    # if data is not an instance of string\n",
    "    if not(isinstance(irisNormDf.select(i).take(1)[0][0], str)):\n",
    "        print(\"Correlation to IND_SPECIES for\", i, irisNormDf.stat.corr(\"IND_SPECIES\", i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to transform the RDD into labelled points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformToLabeledPoint(row):\n",
    "    '''a function to transform data into labeled point'''\n",
    "    lp = (row[\"SPECIES\"],\n",
    "          row[\"IND_SPECIES\"],\n",
    "          Vectors.dense([row['SEPAL_LENGTH'], row[\"SEPAL_WIDTH\"], row[\"PETAL_LENGTH\"], row[\"PETAL_WIDTH\"]]))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irisLp = irisNormDf.rdd.map(transformToLabeledPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irisLpDf = spark.createDataFrame(irisLp, [\"Species\", \"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the dataframe containing labelled points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------------+\n",
      "|species|label|         features|\n",
      "+-------+-----+-----------------+\n",
      "| setosa|  2.0|[5.1,3.5,1.4,0.2]|\n",
      "| setosa|  2.0|[4.9,3.0,1.4,0.2]|\n",
      "| setosa|  2.0|[4.7,3.2,1.3,0.2]|\n",
      "| setosa|  2.0|[4.6,3.1,1.5,0.2]|\n",
      "| setosa|  2.0|[5.0,3.6,1.4,0.2]|\n",
      "| setosa|  2.0|[5.4,3.9,1.7,0.4]|\n",
      "| setosa|  2.0|[4.6,3.4,1.4,0.3]|\n",
      "| setosa|  2.0|[5.0,3.4,1.5,0.2]|\n",
      "| setosa|  2.0|[4.4,2.9,1.4,0.2]|\n",
      "| setosa|  2.0|[4.9,3.1,1.5,0.1]|\n",
      "+-------+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisLpDf.select(\"species\", \"label\", \"features\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PETAL_LENGTH: double, PETAL_WIDTH: double, SEPAL_LENGTH: double, SEPAL_WIDTH: double, SPECIES: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDf.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train & Performance Access the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data train and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = irisLpDf.randomSplit([0.8,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtClassifier = DecisionTreeClassifier(maxDepth=5, labelCol=\"label\", featuresCol=\"features\")\n",
    "dtModel = dtClassifier.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtModel.numNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtModel.depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = dtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------------+--------------+-------------+----------+\n",
      "|   Species|label|         features| rawPrediction|  probability|prediction|\n",
      "+----------+-----+-----------------+--------------+-------------+----------+\n",
      "|    setosa|  2.0|[4.3,3.0,1.1,0.1]|[0.0,0.0,41.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|    setosa|  2.0|[4.4,3.2,1.3,0.2]|[0.0,0.0,41.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|    setosa|  2.0|[4.7,3.2,1.6,0.2]|[0.0,0.0,41.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|    setosa|  2.0|[4.8,3.0,1.4,0.3]|[0.0,0.0,41.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|    setosa|  2.0|[4.9,3.6,1.4,0.1]|[0.0,0.0,41.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|    setosa|  2.0|[5.0,3.5,1.3,0.3]|[0.0,0.0,41.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|    setosa|  2.0|[5.1,3.5,1.4,0.3]|[0.0,0.0,41.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|    setosa|  2.0|[5.1,3.8,1.5,0.3]|[0.0,0.0,41.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|    setosa|  2.0|[5.8,4.0,1.2,0.2]|[0.0,0.0,41.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|versicolor|  0.0|[5.6,2.9,3.6,1.3]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|versicolor|  0.0|[6.3,3.3,4.7,1.6]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|versicolor|  0.0|[5.4,3.0,4.5,1.5]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|versicolor|  0.0|[6.3,2.3,4.4,1.3]|[43.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "| virginica|  1.0|[5.9,3.0,5.1,1.8]|[0.0,38.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| virginica|  1.0|[6.3,3.3,6.0,2.5]|[0.0,38.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| virginica|  1.0|[6.5,3.0,5.5,1.8]|[0.0,38.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| virginica|  1.0|[6.7,3.0,5.2,2.3]|[0.0,38.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| virginica|  1.0|[7.7,3.8,6.7,2.2]|[0.0,38.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "+----------+-----+-----------------+--------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|    5|\n",
      "|  2.0|       2.0|    9|\n",
      "|  0.0|       0.0|    4|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupby(\"label\", \"prediction\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
