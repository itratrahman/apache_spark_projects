{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "# from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spark = SparkSession\\\n",
    "#         .builder\\\n",
    "#         .appName(\"PythonPi\")\\\n",
    "#         .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = ps.SparkContext('local[4]')\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and inspect train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.csv(\n",
    "    \"./input/train.csv\", header=True, mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+\n",
      "|     id|                text|author|\n",
      "+-------+--------------------+------+\n",
      "|id26305|This process, how...|   EAP|\n",
      "|id17569|It never once occ...|   HPL|\n",
      "|id11008|In his left hand ...|   EAP|\n",
      "|id27763|How lovely is spr...|   MWS|\n",
      "|id12958|Finding nothing e...|   HPL|\n",
      "|id22965|A youth passed in...|   MWS|\n",
      "|id09674|The astronomer, p...|   EAP|\n",
      "|id13515|The surcingle hun...|   EAP|\n",
      "|id19322|I knew that you c...|   EAP|\n",
      "|id00912|I confess that ne...|   MWS|\n",
      "|id16737|\"He shall find th...|   MWS|\n",
      "|id16607|Here we barricade...|   EAP|\n",
      "|id19764|Herbert West need...|   HPL|\n",
      "|id18886|The farm like gro...|   HPL|\n",
      "|id17189|But a glance will...|   EAP|\n",
      "|id12799|He had escaped me...|   MWS|\n",
      "|id08441|To these speeches...|   EAP|\n",
      "|id13117|Her native sprigh...|   MWS|\n",
      "|id14862|I even went so fa...|   EAP|\n",
      "|id20836|His facial aspect...|   HPL|\n",
      "+-------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|author|count|\n",
      "+------+-----+\n",
      "|   MWS| 5552|\n",
      "|   HPL| 5451|\n",
      "|   EAP| 7044|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"author\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and inspect test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df =  sqlContext.read.csv(\n",
    "    \"./input/test.csv\", header=True, mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7811"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|     id|                text|\n",
      "+-------+--------------------+\n",
      "|id02310|Still, as I urged...|\n",
      "|id24541|If a fire wanted ...|\n",
      "|id00134|And when they had...|\n",
      "|id27757|While I was think...|\n",
      "|id04081|I am not sure to ...|\n",
      "|id24265|That which is not...|\n",
      "|id25917|I sought for repo...|\n",
      "|id04951|Upon the fourth d...|\n",
      "|id14549|\"\"\"The tone metap...|\n",
      "|id22505|These, the offspr...|\n",
      "|id15181|When I arose trem...|\n",
      "|id21888|And by the shores...|\n",
      "|id12035|Idris heard of he...|\n",
      "|id17991|I say this proudl...|\n",
      "|id00345|At his nod I took...|\n",
      "|id05912|No one doubted no...|\n",
      "|id13443|But although, in ...|\n",
      "|id09248|Festivity, and ev...|\n",
      "|id17542|For I am Iranon, ...|\n",
      "|id25159|I am serious in a...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import nltk modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk, re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract stopwords and create stemmer object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw = set(stopwords.words(\"english\"))\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function for text processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_precessing(text):\n",
    "    \n",
    "    '''a function for preprocessing'''\n",
    "    import string\n",
    "    \n",
    "    translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # replacing the punctuations with no space,which in effect deletes the punctuation marks \n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    # remove stop word\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # stemming\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    text = \" \".join(text) \n",
    "    \n",
    "    # Clean the text\n",
    "    text = re.sub(r\"<br />\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z]\", \" \", text)\n",
    "    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n",
    "    text = re.sub(r\"  \", \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RDD mapping function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_transformation(row):\n",
    "    \n",
    "    iD = row['id']\n",
    "    text = row['text']\n",
    "    if len(row) == 3:    \n",
    "        auth = row['author']\n",
    "    \n",
    "    text = text_precessing(text)\n",
    "    \n",
    "    if len(row) == 3:   \n",
    "        values = Row(id = iD, text = text, author = auth)\n",
    "    else:\n",
    "        values = Row(id = iD, text = text)\n",
    "    \n",
    "    return values    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract RDD from dataframe and apply the mapping function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_rdd = df.rdd\n",
    "test_data_rdd = test_df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_rdd = data_rdd.map(data_transformation)\n",
    "processed_test_rdd = test_data_rdd.map(data_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(author='EAP', id='id26305', text='process howev afford mean ascertain dimens dungeon might make circuit return point whenc set without awar fact perfect uniform seem wall'),\n",
       " Row(author='HPL', id='id17569', text='never occur fumbl might mere mistak'),\n",
       " Row(author='EAP', id='id11008', text='left hand gold snuff box caper hill cut manner fantast step took snuff incess air greatest possibl self satisfact'),\n",
       " Row(author='MWS', id='id27763', text='love spring look windsor terrac sixteen fertil counti spread beneath speckl happi cottag wealthier town look former year heart cheer fair'),\n",
       " Row(author='HPL', id='id12958', text='find noth els even gold superintend abandon attempt perplex look occasion steal counten sit think desk')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='id02310', text='still urg leav ireland inquietud impati father thought best yield'),\n",
       " Row(id='id24541', text='fire want fan could readili fan newspap govern grew weaker doubt leather iron acquir durabl proport short time pair bellow rotterdam ever stood need stitch requir assist hammer'),\n",
       " Row(id='id00134', text='broken frail door found two clean pick human skeleton earthen floor number singular beetl crawl shadowi corner'),\n",
       " Row(id='id27757', text='think possibl manag without one actual tumbl head roll steep side steepl lodg rain gutter ran along eav main build'),\n",
       " Row(id='id04081', text='sure limit knowledg may extend')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turn the processed data back to dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_df = sqlContext.createDataFrame(processed_rdd)\n",
    "processed_test_df = sqlContext.createDataFrame(processed_test_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+\n",
      "|author|     id|                text|\n",
      "+------+-------+--------------------+\n",
      "|   EAP|id26305|process howev aff...|\n",
      "|   HPL|id17569|never occur fumbl...|\n",
      "|   EAP|id11008|left hand gold sn...|\n",
      "|   MWS|id27763|love spring look ...|\n",
      "|   HPL|id12958|find noth els eve...|\n",
      "|   MWS|id22965|youth pass solitu...|\n",
      "|   EAP|id09674|astronom perhap p...|\n",
      "|   EAP|id13515|surcingl hung rib...|\n",
      "|   EAP|id19322|knew could say st...|\n",
      "|   MWS|id00912|confess neither s...|\n",
      "|   MWS|id16737|shall find feel i...|\n",
      "|   EAP|id16607|barricad present ...|\n",
      "|   HPL|id19764|herbert west need...|\n",
      "|   HPL|id18886|farm like ground ...|\n",
      "|   EAP|id17189|glanc show fallac...|\n",
      "|   MWS|id12799|escap must commen...|\n",
      "|   EAP|id08441|speech gave cours...|\n",
      "|   MWS|id13117|nativ sprightli n...|\n",
      "|   EAP|id14862|even went far spe...|\n",
      "|   HPL|id20836|facial aspect rem...|\n",
      "+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|     id|                text|\n",
      "+-------+--------------------+\n",
      "|id02310|still urg leav ir...|\n",
      "|id24541|fire want fan cou...|\n",
      "|id00134|broken frail door...|\n",
      "|id27757|think possibl man...|\n",
      "|id04081|sure limit knowle...|\n",
      "|id24265|matter unless qua...|\n",
      "|id25917|sought repos alth...|\n",
      "|id04951|upon fourth day a...|\n",
      "|id14549|tone metaphys als...|\n",
      "|id22505|offspr later peri...|\n",
      "|id15181|aros trembl know ...|\n",
      "|id21888|shore river zair ...|\n",
      "|id12035|idri heard mother...|\n",
      "|id17991|say proud tear ey...|\n",
      "|id00345|nod took one latt...|\n",
      "|id05912|one doubt mysteri...|\n",
      "|id13443|although one two ...|\n",
      "|id09248|festiv even liber...|\n",
      "|id17542|   iranon princ aira|\n",
      "|id25159|serious assert br...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_test_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import modules for creating TF-IDF matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import CountVectorizer, Tokenizer\n",
    "from pyspark.ml.feature import IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create train validation split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_set, val_set) = processed_df.randomSplit([0.80, 0.20], seed = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create pipeline for train and validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create tokenizer object\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create count vectorizer object\n",
    "cv = CountVectorizer(vocabSize=2**15, inputCol=\"words\", outputCol='cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create tf-idf object\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create string indexer object to transform the categorical output value\n",
    "label_stringIdx = StringIndexer(inputCol = \"author\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, cv, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_fit = pipeline.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the train set\n",
    "train_df = pipeline_fit.transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the validation set\n",
    "val_df = pipeline_fit.transform(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create pipeline for test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_test = Pipeline(stages=[tokenizer, cv, idf])\n",
    "pipeline_test_fit = pipeline_test.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pipeline_test_fit.transform(processed_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the transformed train, validation and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|author|     id|                text|               words|                  cv|            features|label|\n",
      "+------+-------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|   EAP|id00003|burn know incid p...|[burn, know, inci...|(13256,[70,82,239...|(13256,[70,82,239...|  0.0|\n",
      "|   EAP|id00006|difficult given t...|[difficult, given...|(13256,[0,1,4,43,...|(13256,[0,1,4,43,...|  0.0|\n",
      "|   EAP|id00007|cannot maintain e...|[cannot, maintain...|(13256,[3,5,25,14...|(13256,[3,5,25,14...|  0.0|\n",
      "|   EAP|id00012|      deposit coffin|   [deposit, coffin]|(13256,[1143,1229...|(13256,[1143,1229...|  0.0|\n",
      "|   EAP|id00015|ten reason believ...|[ten, reason, bel...|(13256,[182,206,3...|(13256,[182,206,3...|  0.0|\n",
      "|   EAP|id00021|besid thing seen ...|[besid, thing, se...|(13256,[7,113,118...|(13256,[7,113,118...|  0.0|\n",
      "|   EAP|id00024|wyatt parti arriv...|[wyatt, parti, ar...|(13256,[267,277,6...|(13256,[267,277,6...|  0.0|\n",
      "|   EAP|id00032|bodi respect despoil|[bodi, respect, d...|(13256,[110,497,5...|(13256,[110,497,5...|  0.0|\n",
      "|   EAP|id00050|touch upon colleg...|[touch, upon, col...|(13256,[1,556,106...|(13256,[1,556,106...|  0.0|\n",
      "|   EAP|id00053|whole day continu...|[whole, day, cont...|(13256,[8,46,100,...|(13256,[8,46,100,...|  0.0|\n",
      "|   EAP|id00067|sagac first disco...|[sagac, first, di...|(13256,[2,3,7,21,...|(13256,[2,3,7,21,...|  0.0|\n",
      "|   EAP|id00068|place head upon p...|[place, head, upo...|(13256,[1,28,80,2...|(13256,[1,28,80,2...|  0.0|\n",
      "|   EAP|id00080|weigh altogeth ei...|[weigh, altogeth,...|(13256,[478,512,9...|(13256,[478,512,9...|  0.0|\n",
      "|   EAP|id00082|dungeon strang th...|[dungeon, strang,...|(13256,[7,9,85,28...|(13256,[7,9,85,28...|  0.0|\n",
      "|   EAP|id00084|truth could help ...|[truth, could, he...|(13256,[2,19,273,...|(13256,[2,19,273,...|  0.0|\n",
      "|   EAP|id00086|lay remot turret ...|[lay, remot, turr...|(13256,[162,525,7...|(13256,[162,525,7...|  0.0|\n",
      "|   EAP|id00091|attain point ravi...|[attain, point, r...|(13256,[91,108,19...|(13256,[91,108,19...|  0.0|\n",
      "|   EAP|id00099|larger link chain...|[larger, link, ch...|(13256,[66,112,21...|(13256,[66,112,21...|  0.0|\n",
      "|   EAP|id00113|figur fiend aspec...|[figur, fiend, as...|(13256,[40,57,120...|(13256,[40,57,120...|  0.0|\n",
      "|   EAP|id00117|oh quit hero perf...|[oh, quit, hero, ...|(13256,[48,185,33...|(13256,[48,185,33...|  0.0|\n",
      "+------+-------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|author|     id|                text|               words|                  cv|            features|label|\n",
      "+------+-------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|   EAP|id00004|might see perhap ...|[might, see, perh...|(13256,[0,13,49,5...|(13256,[0,13,49,5...|  0.0|\n",
      "|   EAP|id00017|seen pp illustri ...|[seen, pp, illust...|(13256,[21,22,43,...|(13256,[21,22,43,...|  0.0|\n",
      "|   EAP|id00027|      reason conceal|   [reason, conceal]|(13256,[182,647],...|(13256,[182,647],...|  0.0|\n",
      "|   EAP|id00030|dun meantim left ...|[dun, meantim, le...|(13256,[33,71,112...|(13256,[33,71,112...|  0.0|\n",
      "|   EAP|id00034|warehous resort p...|[warehous, resort...|(13256,[28,110,24...|(13256,[28,110,24...|  0.0|\n",
      "|   EAP|id00051|observ although o...|[observ, although...|(13256,[1,9,10,12...|(13256,[1,9,10,12...|  0.0|\n",
      "|   EAP|id00063|pest spirit plagu...|[pest, spirit, pl...|(13256,[45,59,100...|(13256,[45,59,100...|  0.0|\n",
      "|   EAP|id00065|men live die indi...|[men, live, die, ...|(13256,[58,84,103...|(13256,[58,84,103...|  0.0|\n",
      "|   EAP|id00075|tear piec interio...|[tear, piec, inte...|(13256,[0,2,116,2...|(13256,[0,2,116,2...|  0.0|\n",
      "|   EAP|id00123|writer spoke acut...|[writer, spoke, a...|(13256,[52,67,98,...|(13256,[52,67,98,...|  0.0|\n",
      "|   EAP|id00129|fallen tranc abse...|[fallen, tranc, a...|(13256,[2,55,109,...|(13256,[2,55,109,...|  0.0|\n",
      "|   EAP|id00182|mortal bodi lengt...|[mortal, bodi, le...|(13256,[41,110,11...|(13256,[41,110,11...|  0.0|\n",
      "|   EAP|id00238|spoke frequent pe...|[spoke, frequent,...|(13256,[99,109,27...|(13256,[99,109,27...|  0.0|\n",
      "|   EAP|id00280|upon whole judg w...|[upon, whole, jud...|(13256,[0,1,4,49,...|(13256,[0,1,4,49,...|  0.0|\n",
      "|   EAP|id00332|sister howev coul...|[sister, howev, c...|(13256,[2,61,75,6...|(13256,[2,61,75,6...|  0.0|\n",
      "|   EAP|id00334|hand cuf search r...|[hand, cuf, searc...|(13256,[36,41,74,...|(13256,[36,41,74,...|  0.0|\n",
      "|   EAP|id00369|knew midnight wel...|[knew, midnight, ...|(13256,[42,105,16...|(13256,[42,105,16...|  0.0|\n",
      "|   EAP|id00408|saw need impuls p...|[saw, need, impul...|(13256,[32,676,10...|(13256,[32,676,10...|  0.0|\n",
      "|   EAP|id00421|letter deposit wi...|[letter, deposit,...|(13256,[3,18,87,1...|(13256,[3,18,87,1...|  0.0|\n",
      "|   EAP|id00438|grin true diddler...|[grin, true, didd...|(13256,[202,330,1...|(13256,[202,330,1...|  0.0|\n",
      "+------+-------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     id|                text|               words|                  cv|            features|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|id02310|still urg leav ir...|[still, urg, leav...|(13256,[16,29,134...|(13256,[16,29,134...|\n",
      "|id24541|fire want fan cou...|[fire, want, fan,...|(13256,[2,4,55,20...|(13256,[2,4,55,20...|\n",
      "|id00134|broken frail door...|[broken, frail, d...|(13256,[18,49,64,...|(13256,[18,49,64,...|\n",
      "|id27757|think possibl man...|[think, possibl, ...|(13256,[0,62,80,1...|(13256,[0,62,80,1...|\n",
      "|id04081|sure limit knowle...|[sure, limit, kno...|(13256,[53,317,44...|(13256,[53,317,44...|\n",
      "|id24265|matter unless qua...|[matter, unless, ...|(13256,[7,205,905...|(13256,[7,205,905...|\n",
      "|id25917|sought repos alth...|[sought, repos, a...|(13256,[0,78,89,1...|(13256,[0,78,89,1...|\n",
      "|id04951|upon fourth day a...|[upon, fourth, da...|(13256,[1,8,34,35...|(13256,[1,8,34,35...|\n",
      "|id14549|tone metaphys als...|[tone, metaphys, ...|(13256,[0,106,197...|(13256,[0,106,197...|\n",
      "|id22505|offspr later peri...|[offspr, later, p...|(13256,[4,10,54,2...|(13256,[4,10,54,2...|\n",
      "|id15181|aros trembl know ...|[aros, trembl, kn...|(13256,[22,34,37,...|(13256,[22,34,37,...|\n",
      "|id21888|shore river zair ...|[shore, river, za...|(13256,[371,507,5...|(13256,[371,507,5...|\n",
      "|id12035|idri heard mother...|[idri, heard, mot...|(13256,[79,91,298...|(13256,[79,91,298...|\n",
      "|id17991|say proud tear ey...|[say, proud, tear...|(13256,[11,43,311...|(13256,[11,43,311...|\n",
      "|id00345|nod took one latt...|[nod, took, one, ...|(13256,[0,1,113,1...|(13256,[0,1,113,1...|\n",
      "|id05912|one doubt mysteri...|[one, doubt, myst...|(13256,[0,3,51,20...|(13256,[0,3,51,20...|\n",
      "|id13443|although one two ...|[although, one, t...|(13256,[0,2,9,22,...|(13256,[0,2,9,22,...|\n",
      "|id09248|festiv even liber...|[festiv, even, li...|(13256,[5,8,95,37...|(13256,[5,8,95,37...|\n",
      "|id17542|   iranon princ aira|[iranon, princ, a...|(13256,[1667,2034...|(13256,[1667,2034...|\n",
      "|id25159|serious assert br...|[serious, assert,...|(13256,[289,349,3...|(13256,[289,349,3...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit various machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit naive bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and fit model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model = NaiveBayes(featuresCol=\"features\", labelCol=\"label\",  modelType='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model_fitted = nb_model.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model and create submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions1 = nb_model_fitted.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798284449363586"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission1 = nb_model_fitted.transform(test_df)\n",
    "submission1.select([\"id\", \"prediction\"]).toPandas().to_csv('submission1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and fit model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=1000,featuresCol=\"features\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_fitted = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model and create submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions2 = nb_model_fitted.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798284449363586"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission2 = nb_model_fitted.transform(test_df)\n",
    "submission2.select([\"id\", \"prediction\"]).toPandas().to_csv('submission2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and fit model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import OneVsRest, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(featuresCol='features', labelCol='label', maxIter=80, regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_ovr = OneVsRest(classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_fitted = lsvc_ovr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model and create submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions3 = lsvc_fitted.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7230215827338129"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission3 = lsvc_fitted.transform(test_df)\n",
    "submission3.select([\"id\", \"prediction\"]).toPandas().to_csv('submission3.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
